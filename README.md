# 1. Create text data from train data to use fastText embeddings

1. clone fastText from github
2. run `sh create_unsupervised_fastText.sh`

# 2. run `feature_create.ipynb`

Some naive bayes feature and unsupervised fasttext based feature training.

# 3. Download glove and word2vec pre-traiend model.

- run `pre-trained-word-embeddings.ipynb` and `glove-logistic.ipynb`

# 4. Trainined supervised fastText (two models!)

# 5. xgboost

run `xgboost.ipynb`