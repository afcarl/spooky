{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import preprocess\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "import string\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling1D, Embedding, Lambda\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_docs(df, n_gram_max=1):\n",
    "    docs = []\n",
    "    for i, text in enumerate(df.text):    \n",
    "        def add_ngram(q, n_gram_max):\n",
    "            ngrams = []\n",
    "            for n in range(2, n_gram_max+1):\n",
    "                for w_index in range(len(q)-n+1):\n",
    "                    ngrams.append('--'.join(q[w_index:w_index+n]))\n",
    "            return q + ngrams\n",
    "\n",
    "        doc = preprocess(text).split()\n",
    "        docs.append(' '.join(add_ngram(doc, n_gram_max)))\n",
    "        \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./../data/train_feature.csv')\n",
    "df_test = pd.read_csv('./../data/test_feature.csv')\n",
    "text = df.text.values\n",
    "text_test = df_test.text.values\n",
    "\n",
    "author2class = {'EAP': 0, 'HPL' : 1, 'MWS' : 2}\n",
    "class2author = ['EAP', 'HPL', 'MWS']\n",
    "y = np.array([author2class[a] for a in df.author])\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(input_dim, embeddings_dims=20):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=embedding_dims))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5: #Trains: 15663, #Val: 3916 #vocab: 28071  (15663, 512) (3916, 512) (8392, 512)\n",
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/50\n",
      "15663/15663 [==============================] - 9s - loss: 1.0852 - acc: 0.4036 - val_loss: 1.0803 - val_acc: 0.4035\n",
      "Epoch 2/50\n",
      "15663/15663 [==============================] - 10s - loss: 1.0708 - acc: 0.4042 - val_loss: 1.0628 - val_acc: 0.4065\n",
      "Epoch 3/50\n",
      "15663/15663 [==============================] - 12s - loss: 1.0385 - acc: 0.4347 - val_loss: 1.0200 - val_acc: 0.4390\n",
      "Epoch 4/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.9844 - acc: 0.5377 - val_loss: 0.9649 - val_acc: 0.5143\n",
      "Epoch 5/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.9182 - acc: 0.6445 - val_loss: 0.9067 - val_acc: 0.5697\n",
      "Epoch 6/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.8502 - acc: 0.7048 - val_loss: 0.8443 - val_acc: 0.6701\n",
      "Epoch 7/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.7863 - acc: 0.7389 - val_loss: 0.7924 - val_acc: 0.7043\n",
      "Epoch 8/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.7297 - acc: 0.7639 - val_loss: 0.7459 - val_acc: 0.7234\n",
      "Epoch 9/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.6795 - acc: 0.7808 - val_loss: 0.7070 - val_acc: 0.7413\n",
      "Epoch 10/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.6354 - acc: 0.7960 - val_loss: 0.6758 - val_acc: 0.7347\n",
      "Epoch 11/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.5953 - acc: 0.8079 - val_loss: 0.6432 - val_acc: 0.7584\n",
      "Epoch 12/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.5604 - acc: 0.8191 - val_loss: 0.6204 - val_acc: 0.7569\n",
      "Epoch 13/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.5285 - acc: 0.8299 - val_loss: 0.5931 - val_acc: 0.7771\n",
      "Epoch 14/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.4998 - acc: 0.8399 - val_loss: 0.5749 - val_acc: 0.7858\n",
      "Epoch 15/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.4730 - acc: 0.8487 - val_loss: 0.5576 - val_acc: 0.7911\n",
      "Epoch 16/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.4483 - acc: 0.8571 - val_loss: 0.5393 - val_acc: 0.7926\n",
      "Epoch 17/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.4258 - acc: 0.8650 - val_loss: 0.5265 - val_acc: 0.7980\n",
      "Epoch 18/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.4054 - acc: 0.8722 - val_loss: 0.5084 - val_acc: 0.8069\n",
      "Epoch 19/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.3843 - acc: 0.8802 - val_loss: 0.4962 - val_acc: 0.8041\n",
      "Epoch 20/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.3656 - acc: 0.8873 - val_loss: 0.4836 - val_acc: 0.8151\n",
      "Epoch 21/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.3490 - acc: 0.8919 - val_loss: 0.4770 - val_acc: 0.8146\n",
      "Epoch 22/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.3328 - acc: 0.8987 - val_loss: 0.4639 - val_acc: 0.8215\n",
      "Epoch 23/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.3180 - acc: 0.9016 - val_loss: 0.4556 - val_acc: 0.8172\n",
      "Epoch 24/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.3029 - acc: 0.9095 - val_loss: 0.4536 - val_acc: 0.8233\n",
      "Epoch 25/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.2901 - acc: 0.9139 - val_loss: 0.4364 - val_acc: 0.8297\n",
      "Epoch 26/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.2777 - acc: 0.9175 - val_loss: 0.4290 - val_acc: 0.8304\n",
      "Epoch 27/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.2656 - acc: 0.9213 - val_loss: 0.4218 - val_acc: 0.8340\n",
      "Epoch 28/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.2539 - acc: 0.9242 - val_loss: 0.4209 - val_acc: 0.8340\n",
      "Epoch 29/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.2443 - acc: 0.9280 - val_loss: 0.4132 - val_acc: 0.8361\n",
      "Epoch 30/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.2337 - acc: 0.9320 - val_loss: 0.4091 - val_acc: 0.8391\n",
      "Epoch 31/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.2242 - acc: 0.9357 - val_loss: 0.4036 - val_acc: 0.8396\n",
      "Epoch 32/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.2158 - acc: 0.9372 - val_loss: 0.3985 - val_acc: 0.8394\n",
      "Epoch 33/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.2071 - acc: 0.9420 - val_loss: 0.3932 - val_acc: 0.8435\n",
      "Epoch 34/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.1990 - acc: 0.9430 - val_loss: 0.3913 - val_acc: 0.8437\n",
      "Epoch 35/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.1911 - acc: 0.9453 - val_loss: 0.3882 - val_acc: 0.8450\n",
      "Epoch 36/50\n",
      "15663/15663 [==============================] - 12s - loss: 0.1844 - acc: 0.9473 - val_loss: 0.3861 - val_acc: 0.8468\n",
      "Epoch 37/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.1776 - acc: 0.9508 - val_loss: 0.3858 - val_acc: 0.8455\n",
      "Epoch 38/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.1713 - acc: 0.9527 - val_loss: 0.3806 - val_acc: 0.8493\n",
      "Epoch 39/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.1639 - acc: 0.9547 - val_loss: 0.3798 - val_acc: 0.8493\n",
      "Epoch 40/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1590 - acc: 0.9561 - val_loss: 0.3758 - val_acc: 0.8519\n",
      "Epoch 41/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1529 - acc: 0.9578 - val_loss: 0.3790 - val_acc: 0.8519\n",
      "Epoch 42/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1479 - acc: 0.9595 - val_loss: 0.3733 - val_acc: 0.8529\n",
      "Epoch 43/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1429 - acc: 0.9616 - val_loss: 0.3778 - val_acc: 0.8509\n",
      "Epoch 44/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1365 - acc: 0.9637 - val_loss: 0.3748 - val_acc: 0.8516\n",
      "Epoch 45/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1326 - acc: 0.9648 - val_loss: 0.3729 - val_acc: 0.8529\n",
      "Epoch 46/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1280 - acc: 0.9666 - val_loss: 0.3743 - val_acc: 0.8527\n",
      "Epoch 47/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1234 - acc: 0.9661 - val_loss: 0.3746 - val_acc: 0.8524\n",
      "Epoch 48/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1196 - acc: 0.9674 - val_loss: 0.3755 - val_acc: 0.8519\n",
      "Epoch 49/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1154 - acc: 0.9696 - val_loss: 0.3706 - val_acc: 0.8557\n",
      "Epoch 50/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1115 - acc: 0.9708 - val_loss: 0.3906 - val_acc: 0.8417\n",
      "3840/3916 [============================>.] - ETA: 0svalLoss: 0.37058353491623575\n",
      "8160/8392 [============================>.] - ETA: 0s2/5: #Trains: 15663, #Val: 3916 #vocab: 28071  (15663, 512) (3916, 512) (8392, 512)\n",
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/50\n",
      "15663/15663 [==============================] - 8s - loss: 1.0848 - acc: 0.4013 - val_loss: 1.0782 - val_acc: 0.4037\n",
      "Epoch 2/50\n",
      "15663/15663 [==============================] - 9s - loss: 1.0679 - acc: 0.4069 - val_loss: 1.0539 - val_acc: 0.4114\n",
      "Epoch 3/50\n",
      "15663/15663 [==============================] - 8s - loss: 1.0298 - acc: 0.4565 - val_loss: 1.0064 - val_acc: 0.5148\n",
      "Epoch 4/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.9730 - acc: 0.5613 - val_loss: 0.9483 - val_acc: 0.6136\n",
      "Epoch 5/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.9091 - acc: 0.6461 - val_loss: 0.8896 - val_acc: 0.6297\n",
      "Epoch 6/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.8454 - acc: 0.7054 - val_loss: 0.8341 - val_acc: 0.7270\n",
      "Epoch 7/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.7860 - acc: 0.7391 - val_loss: 0.7851 - val_acc: 0.6966\n",
      "Epoch 8/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.7321 - acc: 0.7588 - val_loss: 0.7399 - val_acc: 0.7538\n",
      "Epoch 9/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.6840 - acc: 0.7776 - val_loss: 0.7007 - val_acc: 0.7623\n",
      "Epoch 10/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.6411 - acc: 0.7913 - val_loss: 0.6699 - val_acc: 0.7541\n",
      "Epoch 11/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.6026 - acc: 0.8044 - val_loss: 0.6374 - val_acc: 0.7755\n",
      "Epoch 12/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.5666 - acc: 0.8145 - val_loss: 0.6125 - val_acc: 0.7829\n",
      "Epoch 13/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.5353 - acc: 0.8265 - val_loss: 0.5962 - val_acc: 0.7737\n",
      "Epoch 14/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.5054 - acc: 0.8353 - val_loss: 0.5731 - val_acc: 0.7957\n",
      "Epoch 15/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.4783 - acc: 0.8465 - val_loss: 0.5483 - val_acc: 0.7995\n",
      "Epoch 16/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.4529 - acc: 0.8553 - val_loss: 0.5300 - val_acc: 0.8001\n",
      "Epoch 17/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.4288 - acc: 0.8655 - val_loss: 0.5262 - val_acc: 0.7919\n",
      "Epoch 18/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.4068 - acc: 0.8743 - val_loss: 0.5012 - val_acc: 0.8144\n",
      "Epoch 19/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.3860 - acc: 0.8790 - val_loss: 0.4963 - val_acc: 0.8044\n",
      "Epoch 20/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.3667 - acc: 0.8885 - val_loss: 0.4813 - val_acc: 0.8212\n",
      "Epoch 21/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.3486 - acc: 0.8941 - val_loss: 0.4652 - val_acc: 0.8197\n",
      "Epoch 22/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.3318 - acc: 0.9009 - val_loss: 0.4523 - val_acc: 0.8292\n",
      "Epoch 23/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.3155 - acc: 0.9063 - val_loss: 0.4459 - val_acc: 0.8292\n",
      "Epoch 24/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.3010 - acc: 0.9101 - val_loss: 0.4350 - val_acc: 0.8384\n",
      "Epoch 25/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.2870 - acc: 0.9173 - val_loss: 0.4290 - val_acc: 0.8371\n",
      "Epoch 26/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.2741 - acc: 0.9207 - val_loss: 0.4222 - val_acc: 0.8315\n",
      "Epoch 27/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.2622 - acc: 0.9249 - val_loss: 0.4125 - val_acc: 0.8414\n",
      "Epoch 28/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.2513 - acc: 0.9282 - val_loss: 0.4067 - val_acc: 0.8422\n",
      "Epoch 29/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.2391 - acc: 0.9309 - val_loss: 0.4064 - val_acc: 0.8465\n",
      "Epoch 30/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.2296 - acc: 0.9349 - val_loss: 0.4006 - val_acc: 0.8399\n",
      "Epoch 31/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.2197 - acc: 0.9384 - val_loss: 0.4033 - val_acc: 0.8430\n",
      "Epoch 32/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.2105 - acc: 0.9396 - val_loss: 0.3887 - val_acc: 0.8483\n",
      "Epoch 33/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.2020 - acc: 0.9414 - val_loss: 0.3845 - val_acc: 0.8539\n",
      "Epoch 34/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1944 - acc: 0.9444 - val_loss: 0.3907 - val_acc: 0.8450\n",
      "Epoch 35/50\n",
      "15663/15663 [==============================] - 7s - loss: 0.1859 - acc: 0.9490 - val_loss: 0.3828 - val_acc: 0.8509\n",
      "Epoch 36/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1784 - acc: 0.9515 - val_loss: 0.3814 - val_acc: 0.8496\n",
      "Epoch 37/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1722 - acc: 0.9522 - val_loss: 0.3800 - val_acc: 0.8468\n",
      "Epoch 38/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1651 - acc: 0.9528 - val_loss: 0.3743 - val_acc: 0.8539\n",
      "Epoch 39/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1591 - acc: 0.9546 - val_loss: 0.3726 - val_acc: 0.8519\n",
      "Epoch 40/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1532 - acc: 0.9581 - val_loss: 0.3735 - val_acc: 0.8516\n",
      "Epoch 41/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1473 - acc: 0.9591 - val_loss: 0.3751 - val_acc: 0.8509\n",
      "Epoch 42/50\n",
      "15663/15663 [==============================] - 7s - loss: 0.1428 - acc: 0.9595 - val_loss: 0.3755 - val_acc: 0.8547\n",
      "Epoch 43/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1373 - acc: 0.9614 - val_loss: 0.3667 - val_acc: 0.8570\n",
      "Epoch 44/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.1327 - acc: 0.9639 - val_loss: 0.3662 - val_acc: 0.8560\n",
      "Epoch 45/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1271 - acc: 0.9658 - val_loss: 0.3670 - val_acc: 0.8555\n",
      "Epoch 46/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1226 - acc: 0.9657 - val_loss: 0.3674 - val_acc: 0.8544\n",
      "Epoch 47/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.1182 - acc: 0.9673 - val_loss: 0.3715 - val_acc: 0.8547\n",
      "Epoch 48/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.1143 - acc: 0.9696 - val_loss: 0.3669 - val_acc: 0.8547\n",
      "Epoch 49/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1104 - acc: 0.9699 - val_loss: 0.3689 - val_acc: 0.8565\n",
      "3776/3916 [===========================>..] - ETA: 0svalLoss: 0.3683976634282521\n",
      "8288/8392 [============================>.] - ETA: 0s3/5: #Trains: 15663, #Val: 3916 #vocab: 28071  (15663, 512) (3916, 512) (8392, 512)\n",
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/50\n",
      "15663/15663 [==============================] - 10s - loss: 1.0859 - acc: 0.4009 - val_loss: 1.0789 - val_acc: 0.4096\n",
      "Epoch 2/50\n",
      "15663/15663 [==============================] - 10s - loss: 1.0738 - acc: 0.4046 - val_loss: 1.0621 - val_acc: 0.4096\n",
      "Epoch 3/50\n",
      "15663/15663 [==============================] - 10s - loss: 1.0441 - acc: 0.4332 - val_loss: 1.0218 - val_acc: 0.4740\n",
      "Epoch 4/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.9921 - acc: 0.5187 - val_loss: 0.9687 - val_acc: 0.6287\n",
      "Epoch 5/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.9267 - acc: 0.6171 - val_loss: 0.9075 - val_acc: 0.6744\n",
      "Epoch 6/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.8576 - acc: 0.6924 - val_loss: 0.8474 - val_acc: 0.6433\n",
      "Epoch 7/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.7919 - acc: 0.7365 - val_loss: 0.7889 - val_acc: 0.6938\n",
      "Epoch 8/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.7325 - acc: 0.7583 - val_loss: 0.7446 - val_acc: 0.7515\n",
      "Epoch 9/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.6817 - acc: 0.7779 - val_loss: 0.7029 - val_acc: 0.7337\n",
      "Epoch 10/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.6355 - acc: 0.7917 - val_loss: 0.6683 - val_acc: 0.7536\n",
      "Epoch 11/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.5959 - acc: 0.8055 - val_loss: 0.6377 - val_acc: 0.7656\n",
      "Epoch 12/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.5596 - acc: 0.8171 - val_loss: 0.6166 - val_acc: 0.7778\n",
      "Epoch 13/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.5263 - acc: 0.8306 - val_loss: 0.5904 - val_acc: 0.7758\n",
      "Epoch 14/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.4974 - acc: 0.8355 - val_loss: 0.5684 - val_acc: 0.7939\n",
      "Epoch 15/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.4698 - acc: 0.8473 - val_loss: 0.5501 - val_acc: 0.7995\n",
      "Epoch 16/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.4445 - acc: 0.8575 - val_loss: 0.5359 - val_acc: 0.7919\n",
      "Epoch 17/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.4206 - acc: 0.8646 - val_loss: 0.5179 - val_acc: 0.8021\n",
      "Epoch 18/50\n",
      "15663/15663 [==============================] - 12s - loss: 0.3988 - acc: 0.8722 - val_loss: 0.5053 - val_acc: 0.8085\n",
      "Epoch 19/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.3792 - acc: 0.8803 - val_loss: 0.4920 - val_acc: 0.8154\n",
      "Epoch 20/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.3600 - acc: 0.8876 - val_loss: 0.4841 - val_acc: 0.8133\n",
      "Epoch 21/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.3423 - acc: 0.8936 - val_loss: 0.4717 - val_acc: 0.8230\n",
      "Epoch 22/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.3257 - acc: 0.9001 - val_loss: 0.4550 - val_acc: 0.8289\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15663/15663 [==============================] - 10s - loss: 0.3100 - acc: 0.9058 - val_loss: 0.4464 - val_acc: 0.8312\n",
      "Epoch 24/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.2954 - acc: 0.9120 - val_loss: 0.4385 - val_acc: 0.8292\n",
      "Epoch 25/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.2812 - acc: 0.9157 - val_loss: 0.4302 - val_acc: 0.8345\n",
      "Epoch 26/50\n",
      "15663/15663 [==============================] - 12s - loss: 0.2678 - acc: 0.9209 - val_loss: 0.4224 - val_acc: 0.8373\n",
      "Epoch 27/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.2562 - acc: 0.9255 - val_loss: 0.4204 - val_acc: 0.8373\n",
      "Epoch 28/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.2446 - acc: 0.9278 - val_loss: 0.4104 - val_acc: 0.8396\n",
      "Epoch 29/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.2342 - acc: 0.9323 - val_loss: 0.4049 - val_acc: 0.8432\n",
      "Epoch 30/50\n",
      "15663/15663 [==============================] - 14s - loss: 0.2240 - acc: 0.9350 - val_loss: 0.4051 - val_acc: 0.8424\n",
      "Epoch 31/50\n",
      "15663/15663 [==============================] - 12s - loss: 0.2143 - acc: 0.9379 - val_loss: 0.3957 - val_acc: 0.8450\n",
      "Epoch 32/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.2056 - acc: 0.9408 - val_loss: 0.3925 - val_acc: 0.8460\n",
      "Epoch 33/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.1968 - acc: 0.9441 - val_loss: 0.3952 - val_acc: 0.8422\n",
      "Epoch 34/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.1892 - acc: 0.9461 - val_loss: 0.3941 - val_acc: 0.8460\n",
      "Epoch 35/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1805 - acc: 0.9487 - val_loss: 0.3826 - val_acc: 0.8493\n",
      "Epoch 36/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.1731 - acc: 0.9509 - val_loss: 0.3855 - val_acc: 0.8473\n",
      "Epoch 37/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1669 - acc: 0.9528 - val_loss: 0.3774 - val_acc: 0.8501\n",
      "Epoch 38/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1609 - acc: 0.9535 - val_loss: 0.3761 - val_acc: 0.8504\n",
      "Epoch 39/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1538 - acc: 0.9570 - val_loss: 0.3739 - val_acc: 0.8521\n",
      "Epoch 40/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1486 - acc: 0.9581 - val_loss: 0.3732 - val_acc: 0.8529\n",
      "Epoch 41/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1424 - acc: 0.9603 - val_loss: 0.3764 - val_acc: 0.8493\n",
      "Epoch 42/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1381 - acc: 0.9613 - val_loss: 0.3841 - val_acc: 0.8414\n",
      "Epoch 43/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1323 - acc: 0.9626 - val_loss: 0.3767 - val_acc: 0.8516\n",
      "Epoch 44/50\n",
      "15663/15663 [==============================] - 7s - loss: 0.1274 - acc: 0.9649 - val_loss: 0.3799 - val_acc: 0.8470\n",
      "Epoch 45/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1239 - acc: 0.9653 - val_loss: 0.3708 - val_acc: 0.8537\n",
      "Epoch 46/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1189 - acc: 0.9670 - val_loss: 0.3707 - val_acc: 0.8514\n",
      "Epoch 47/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1146 - acc: 0.9691 - val_loss: 0.3862 - val_acc: 0.8455\n",
      "Epoch 48/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1107 - acc: 0.9685 - val_loss: 0.3721 - val_acc: 0.8542\n",
      "Epoch 49/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1057 - acc: 0.9704 - val_loss: 0.3871 - val_acc: 0.8465\n",
      "Epoch 50/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1026 - acc: 0.9715 - val_loss: 0.3837 - val_acc: 0.8496\n",
      "3712/3916 [===========================>..] - ETA: 0svalLoss: 0.36915629266697264\n",
      "8352/8392 [============================>.] - ETA: 0s4/5: #Trains: 15663, #Val: 3916 #vocab: 28071  (15663, 512) (3916, 512) (8392, 512)\n",
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/50\n",
      "15663/15663 [==============================] - 8s - loss: 1.0858 - acc: 0.3997 - val_loss: 1.0838 - val_acc: 0.3996\n",
      "Epoch 2/50\n",
      "15663/15663 [==============================] - 8s - loss: 1.0701 - acc: 0.4106 - val_loss: 1.0624 - val_acc: 0.4139\n",
      "Epoch 3/50\n",
      "15663/15663 [==============================] - 8s - loss: 1.0326 - acc: 0.4779 - val_loss: 1.0190 - val_acc: 0.4778\n",
      "Epoch 4/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.9732 - acc: 0.5431 - val_loss: 0.9627 - val_acc: 0.5217\n",
      "Epoch 5/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.9058 - acc: 0.5985 - val_loss: 0.9090 - val_acc: 0.5644\n",
      "Epoch 6/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.8402 - acc: 0.6588 - val_loss: 0.8538 - val_acc: 0.6660\n",
      "Epoch 7/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.7782 - acc: 0.7213 - val_loss: 0.8032 - val_acc: 0.6486\n",
      "Epoch 8/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.7217 - acc: 0.7515 - val_loss: 0.7522 - val_acc: 0.7334\n",
      "Epoch 9/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.6703 - acc: 0.7774 - val_loss: 0.7105 - val_acc: 0.7531\n",
      "Epoch 10/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.6253 - acc: 0.7935 - val_loss: 0.6749 - val_acc: 0.7615\n",
      "Epoch 11/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.5846 - acc: 0.8094 - val_loss: 0.6427 - val_acc: 0.7783\n",
      "Epoch 12/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.5479 - acc: 0.8213 - val_loss: 0.6243 - val_acc: 0.7692\n",
      "Epoch 13/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.5143 - acc: 0.8328 - val_loss: 0.5897 - val_acc: 0.7842\n",
      "Epoch 14/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.4846 - acc: 0.8434 - val_loss: 0.5675 - val_acc: 0.7891\n",
      "Epoch 15/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.4557 - acc: 0.8572 - val_loss: 0.5450 - val_acc: 0.8013\n",
      "Epoch 16/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.4306 - acc: 0.8636 - val_loss: 0.5275 - val_acc: 0.8041\n",
      "Epoch 17/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.4070 - acc: 0.8728 - val_loss: 0.5107 - val_acc: 0.8138\n",
      "Epoch 18/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.3847 - acc: 0.8791 - val_loss: 0.4929 - val_acc: 0.8230\n",
      "Epoch 19/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.3647 - acc: 0.8866 - val_loss: 0.4831 - val_acc: 0.8169\n",
      "Epoch 20/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.3455 - acc: 0.8917 - val_loss: 0.4725 - val_acc: 0.8174\n",
      "Epoch 21/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.3269 - acc: 0.9006 - val_loss: 0.4601 - val_acc: 0.8251\n",
      "Epoch 22/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.3107 - acc: 0.9047 - val_loss: 0.4439 - val_acc: 0.8322\n",
      "Epoch 23/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.2948 - acc: 0.9100 - val_loss: 0.4423 - val_acc: 0.8320\n",
      "Epoch 24/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.2796 - acc: 0.9163 - val_loss: 0.4240 - val_acc: 0.8401\n",
      "Epoch 25/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.2667 - acc: 0.9197 - val_loss: 0.4222 - val_acc: 0.8378\n",
      "Epoch 26/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.2540 - acc: 0.9240 - val_loss: 0.4091 - val_acc: 0.8422\n",
      "Epoch 27/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.2412 - acc: 0.9294 - val_loss: 0.4094 - val_acc: 0.8427\n",
      "Epoch 28/50\n",
      "15663/15663 [==============================] - 7s - loss: 0.2297 - acc: 0.9314 - val_loss: 0.3997 - val_acc: 0.8445\n",
      "Epoch 29/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.2182 - acc: 0.9367 - val_loss: 0.3936 - val_acc: 0.8455\n",
      "Epoch 30/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.2086 - acc: 0.9394 - val_loss: 0.3923 - val_acc: 0.8430\n",
      "Epoch 31/50\n",
      "15663/15663 [==============================] - 7s - loss: 0.1994 - acc: 0.9423 - val_loss: 0.3844 - val_acc: 0.8486\n",
      "Epoch 32/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.1904 - acc: 0.9454 - val_loss: 0.3827 - val_acc: 0.8496\n",
      "Epoch 33/50\n",
      "15663/15663 [==============================] - 8s - loss: 0.1832 - acc: 0.9460 - val_loss: 0.3775 - val_acc: 0.8504\n",
      "Epoch 34/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.1750 - acc: 0.9496 - val_loss: 0.3858 - val_acc: 0.8440\n",
      "Epoch 35/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.1667 - acc: 0.9503 - val_loss: 0.3785 - val_acc: 0.8537\n",
      "Epoch 36/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.1597 - acc: 0.9539 - val_loss: 0.3704 - val_acc: 0.8534\n",
      "Epoch 37/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.1525 - acc: 0.9559 - val_loss: 0.3673 - val_acc: 0.8519\n",
      "Epoch 38/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.1460 - acc: 0.9593 - val_loss: 0.3695 - val_acc: 0.8529\n",
      "Epoch 39/50\n",
      "15663/15663 [==============================] - 10s - loss: 0.1404 - acc: 0.9610 - val_loss: 0.4100 - val_acc: 0.8330\n",
      "Epoch 40/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.1345 - acc: 0.9623 - val_loss: 0.3697 - val_acc: 0.8529\n",
      "Epoch 41/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.1291 - acc: 0.9657 - val_loss: 0.3639 - val_acc: 0.8539\n",
      "Epoch 42/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.1233 - acc: 0.9664 - val_loss: 0.3646 - val_acc: 0.8547\n",
      "Epoch 43/50\n",
      "15663/15663 [==============================] - 11s - loss: 0.1186 - acc: 0.9674 - val_loss: 0.3725 - val_acc: 0.8542\n",
      "Epoch 44/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1138 - acc: 0.9695 - val_loss: 0.3667 - val_acc: 0.8562\n",
      "Epoch 45/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1099 - acc: 0.9702 - val_loss: 0.3654 - val_acc: 0.8565\n",
      "Epoch 46/50\n",
      "15663/15663 [==============================] - 9s - loss: 0.1056 - acc: 0.9731 - val_loss: 0.3731 - val_acc: 0.8542\n",
      "3552/3916 [==========================>...] - ETA: 0svalLoss: 0.3678449922771862\n",
      "8192/8392 [============================>.] - ETA: 0s5/5: #Trains: 15664, #Val: 3915 #vocab: 28071  (15664, 512) (3915, 512) (8392, 512)\n",
      "Train on 15664 samples, validate on 3915 samples\n",
      "Epoch 1/50\n",
      "15664/15664 [==============================] - 9s - loss: 1.0855 - acc: 0.4030 - val_loss: 1.0817 - val_acc: 0.4020\n",
      "Epoch 2/50\n",
      "15664/15664 [==============================] - 9s - loss: 1.0718 - acc: 0.4056 - val_loss: 1.0617 - val_acc: 0.4120\n",
      "Epoch 3/50\n",
      "15664/15664 [==============================] - 10s - loss: 1.0378 - acc: 0.4425 - val_loss: 1.0179 - val_acc: 0.5014\n",
      "Epoch 4/50\n",
      "15664/15664 [==============================] - 9s - loss: 0.9795 - acc: 0.5420 - val_loss: 0.9562 - val_acc: 0.5727\n",
      "Epoch 5/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.9100 - acc: 0.6353 - val_loss: 0.8943 - val_acc: 0.6299\n",
      "Epoch 6/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.8398 - acc: 0.7021 - val_loss: 0.8329 - val_acc: 0.6966\n",
      "Epoch 7/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.7760 - acc: 0.7416 - val_loss: 0.7831 - val_acc: 0.6797\n",
      "Epoch 8/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.7183 - acc: 0.7656 - val_loss: 0.7307 - val_acc: 0.7479\n",
      "Epoch 9/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.6674 - acc: 0.7841 - val_loss: 0.6939 - val_acc: 0.7637\n",
      "Epoch 10/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.6227 - acc: 0.7986 - val_loss: 0.6591 - val_acc: 0.7727\n",
      "Epoch 11/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.5831 - acc: 0.8111 - val_loss: 0.6285 - val_acc: 0.7803\n",
      "Epoch 12/50\n",
      "15664/15664 [==============================] - 9s - loss: 0.5469 - acc: 0.8243 - val_loss: 0.5994 - val_acc: 0.7839\n",
      "Epoch 13/50\n",
      "15664/15664 [==============================] - 9s - loss: 0.5147 - acc: 0.8348 - val_loss: 0.5845 - val_acc: 0.7691\n",
      "Epoch 14/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.4848 - acc: 0.8444 - val_loss: 0.5661 - val_acc: 0.7959\n",
      "Epoch 15/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.4582 - acc: 0.8529 - val_loss: 0.5357 - val_acc: 0.8095\n",
      "Epoch 16/50\n",
      "15664/15664 [==============================] - 9s - loss: 0.4322 - acc: 0.8633 - val_loss: 0.5207 - val_acc: 0.8082\n",
      "Epoch 17/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.4095 - acc: 0.8693 - val_loss: 0.5110 - val_acc: 0.8128\n",
      "Epoch 18/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.3874 - acc: 0.8778 - val_loss: 0.4946 - val_acc: 0.8135\n",
      "Epoch 19/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.3679 - acc: 0.8842 - val_loss: 0.4808 - val_acc: 0.8199\n",
      "Epoch 20/50\n",
      "15664/15664 [==============================] - 9s - loss: 0.3489 - acc: 0.8913 - val_loss: 0.4695 - val_acc: 0.8217\n",
      "Epoch 21/50\n",
      "15664/15664 [==============================] - 9s - loss: 0.3313 - acc: 0.8980 - val_loss: 0.4590 - val_acc: 0.8281\n",
      "Epoch 22/50\n",
      "15664/15664 [==============================] - 9s - loss: 0.3153 - acc: 0.9048 - val_loss: 0.4519 - val_acc: 0.8253\n",
      "Epoch 23/50\n",
      "15664/15664 [==============================] - 10s - loss: 0.3003 - acc: 0.9083 - val_loss: 0.4407 - val_acc: 0.8375\n",
      "Epoch 24/50\n",
      "15664/15664 [==============================] - 11s - loss: 0.2864 - acc: 0.9145 - val_loss: 0.4345 - val_acc: 0.8381\n",
      "Epoch 25/50\n",
      "15664/15664 [==============================] - 11s - loss: 0.2727 - acc: 0.9205 - val_loss: 0.4243 - val_acc: 0.8391\n",
      "Epoch 26/50\n",
      "15664/15664 [==============================] - 11s - loss: 0.2603 - acc: 0.9241 - val_loss: 0.4194 - val_acc: 0.8388\n",
      "Epoch 27/50\n",
      "15664/15664 [==============================] - 11s - loss: 0.2489 - acc: 0.9255 - val_loss: 0.4204 - val_acc: 0.8383\n",
      "Epoch 28/50\n",
      "15664/15664 [==============================] - 10s - loss: 0.2373 - acc: 0.9291 - val_loss: 0.4066 - val_acc: 0.8421\n",
      "Epoch 29/50\n",
      "15664/15664 [==============================] - 10s - loss: 0.2270 - acc: 0.9351 - val_loss: 0.4024 - val_acc: 0.8424\n",
      "Epoch 30/50\n",
      "15664/15664 [==============================] - 10s - loss: 0.2173 - acc: 0.9374 - val_loss: 0.3981 - val_acc: 0.8455\n",
      "Epoch 31/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.2075 - acc: 0.9425 - val_loss: 0.3941 - val_acc: 0.8470\n",
      "Epoch 32/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.1993 - acc: 0.9441 - val_loss: 0.3962 - val_acc: 0.8393\n",
      "Epoch 33/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.1903 - acc: 0.9466 - val_loss: 0.3887 - val_acc: 0.8475\n",
      "Epoch 34/50\n",
      "15664/15664 [==============================] - 9s - loss: 0.1824 - acc: 0.9485 - val_loss: 0.3874 - val_acc: 0.8490\n",
      "Epoch 35/50\n",
      "15664/15664 [==============================] - 9s - loss: 0.1757 - acc: 0.9499 - val_loss: 0.3919 - val_acc: 0.8352\n",
      "Epoch 36/50\n",
      "15664/15664 [==============================] - 9s - loss: 0.1686 - acc: 0.9521 - val_loss: 0.3824 - val_acc: 0.8503\n",
      "Epoch 37/50\n",
      "15664/15664 [==============================] - 10s - loss: 0.1613 - acc: 0.9546 - val_loss: 0.3885 - val_acc: 0.8480\n",
      "Epoch 38/50\n",
      "15664/15664 [==============================] - 9s - loss: 0.1553 - acc: 0.9569 - val_loss: 0.3818 - val_acc: 0.8511\n",
      "Epoch 39/50\n",
      "15664/15664 [==============================] - 9s - loss: 0.1491 - acc: 0.9580 - val_loss: 0.3865 - val_acc: 0.8475\n",
      "Epoch 40/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.1435 - acc: 0.9602 - val_loss: 0.3850 - val_acc: 0.8490\n",
      "Epoch 41/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.1374 - acc: 0.9623 - val_loss: 0.3823 - val_acc: 0.8460\n",
      "Epoch 42/50\n",
      "15664/15664 [==============================] - 9s - loss: 0.1321 - acc: 0.9627 - val_loss: 0.3776 - val_acc: 0.8501\n",
      "Epoch 43/50\n",
      "15664/15664 [==============================] - 10s - loss: 0.1278 - acc: 0.9650 - val_loss: 0.3775 - val_acc: 0.8544\n",
      "Epoch 44/50\n",
      "15664/15664 [==============================] - 9s - loss: 0.1224 - acc: 0.9668 - val_loss: 0.3810 - val_acc: 0.8496\n",
      "Epoch 45/50\n",
      "15664/15664 [==============================] - 10s - loss: 0.1179 - acc: 0.9672 - val_loss: 0.3771 - val_acc: 0.8549\n",
      "Epoch 46/50\n",
      "15664/15664 [==============================] - 10s - loss: 0.1129 - acc: 0.9687 - val_loss: 0.3794 - val_acc: 0.8539\n",
      "Epoch 47/50\n",
      "15664/15664 [==============================] - 10s - loss: 0.1091 - acc: 0.9711 - val_loss: 0.3787 - val_acc: 0.8529\n",
      "Epoch 48/50\n",
      "15664/15664 [==============================] - 9s - loss: 0.1052 - acc: 0.9717 - val_loss: 0.3809 - val_acc: 0.8524\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15664/15664 [==============================] - 8s - loss: 0.1021 - acc: 0.9723 - val_loss: 0.3852 - val_acc: 0.8519\n",
      "Epoch 50/50\n",
      "15664/15664 [==============================] - 8s - loss: 0.0988 - acc: 0.9729 - val_loss: 0.3823 - val_acc: 0.8547\n",
      "2112/3915 [===============>..............] - ETA: 0svalLoss: 0.3697055116283014\n",
      "8320/8392 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "n_gram_max = 1\n",
    "embedding_dims = 10\n",
    "\n",
    "raw_docs = create_docs(df, n_gram_max=n_gram_max)\n",
    "raw_docs_test = create_docs(df_test, n_gram_max=n_gram_max)\n",
    "\n",
    "seed = 7\n",
    "num_split = 5\n",
    "epochs = 50\n",
    "\n",
    "# for next training\n",
    "predict_prob_features = np.zeros((len(df), 3))\n",
    "predict_prob_features_test = np.zeros((len(df_test), 3))\n",
    "\n",
    "ite = 0\n",
    "sum_loss = 0.\n",
    "min_count = 1\n",
    "\n",
    "kf = KFold(n_splits=num_split, random_state=seed, shuffle=True)\n",
    "for train_index, val_index in kf.split(text):\n",
    "    ite += 1\n",
    "    print('{}/{}: #Trains: {}, #Val: {}'.format(ite, num_split, len(train_index), len(val_index)), end=' ')\n",
    "    \n",
    "    docs_train = [raw_docs[i] for i in train_index]\n",
    "    docs_val = [raw_docs[i] for i in val_index]\n",
    "\n",
    "    # get vocab\n",
    "    tokenizer = Tokenizer(filters='', lower=False)\n",
    "    tokenizer.fit_on_texts(docs_train + docs_val)\n",
    "\n",
    "    num_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=num_words, filters='', lower=False)\n",
    "    tokenizer.fit_on_texts(docs_train + docs_val)    \n",
    "\n",
    "    docs_train = tokenizer.texts_to_sequences(docs_train)\n",
    "    docs_val   = tokenizer.texts_to_sequences(docs_val)\n",
    "    docs_test  = tokenizer.texts_to_sequences(raw_docs_test)\n",
    "\n",
    "    maxlen = 512\n",
    "    #     maxlen = max([len(i) for i in  docs_train] + [len(i) for i in  docs_val])\n",
    "    x_train = pad_sequences(sequences=docs_train, maxlen=maxlen)\n",
    "    x_val = pad_sequences(sequences=docs_val, maxlen=maxlen)\n",
    "    x_test = pad_sequences(sequences=docs_test, maxlen=maxlen)\n",
    "\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    input_dim = max(np.max(x_train), np.max(x_val)) + 1\n",
    "    print('#vocab: {} '.format(num_words), end=' ')\n",
    "    print(x_train.shape, x_val.shape, x_test.shape)\n",
    "    \n",
    "\n",
    "    model = create_model(input_dim)\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath='./../fasttext_weights/weights.hdf5', verbose=0, save_best_only=True)\n",
    "\n",
    "    hist = model.fit(x_train, y_train,\n",
    "                     batch_size=16,\n",
    "                     validation_data=(x_val, y_val),\n",
    "                     epochs=epochs,\n",
    "                     callbacks=[EarlyStopping(patience=4, monitor='val_loss'), \n",
    "                                checkpointer])\n",
    "\n",
    "    # load best weights\n",
    "    model.load_weights('./../fasttext_weights/weights.hdf5')\n",
    "    y_pred = model.predict_proba(x_val)\n",
    "    sum_loss += log_loss(y_pred=y_pred, y_true=np.nonzero(y_val)[1])\n",
    "    \n",
    "    print('valLoss: {}'.format(sum_loss/ite))\n",
    "\n",
    "\n",
    "    # save features\n",
    "    predict_prob_features[val_index] = y_pred\n",
    "    predict_prob_features_test += model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for a, c in author2class.items():\n",
    "    df['{}_fasttext_unigram'.format(a)] = predict_prob_features[:, c]\n",
    "    df_test['{}_fasttext_unigram'.format(a)] = predict_prob_features_test[:, c]/num_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('./../data/train_feature.csv')\n",
    "df_test.to_csv('./../data/test_feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
