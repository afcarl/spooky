{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import preprocess, Tokenizer4keras, create_fastText_model\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "import string\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./../data/train_feature.csv')\n",
    "df_test = pd.read_csv('./../data/test_feature.csv')\n",
    "df_train_texts = df_train.text.values\n",
    "df_test_tests = df_test.text.values\n",
    "\n",
    "author2class = {'EAP': 0, 'HPL' : 1, 'MWS' : 2}\n",
    "class2author = ['EAP', 'HPL', 'MWS']\n",
    "y = np.array([author2class[a] for a in df_train.author])\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocessin parameters\n",
    "n_gram_max = 1\n",
    "min_count = 1\n",
    "maxlen = 512\n",
    "\n",
    "tokenizer = Tokenizer4keras(maxlen=maxlen, min_count=min_count, n_gram_max=n_gram_max, lower=False, single=False, add_ngram_first=True)\n",
    "x = tokenizer.fit_transform(df_texts=df_train_texts)\n",
    "x_test = tokenizer.transofrm(df_test_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5: #Trains: 15663, #Val: 3916 (15663, 512) (3916, 512) (8392, 512)\n",
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/60\n",
      "15663/15663 [==============================] - 12s - loss: 1.0852 - acc: 0.4037 - val_loss: 1.0803 - val_acc: 0.4035\n",
      "Epoch 2/60\n",
      "15663/15663 [==============================] - 11s - loss: 1.0709 - acc: 0.4042 - val_loss: 1.0630 - val_acc: 0.4063\n",
      "Epoch 3/60\n",
      "15663/15663 [==============================] - 8s - loss: 1.0388 - acc: 0.4340 - val_loss: 1.0205 - val_acc: 0.4385\n",
      "Epoch 4/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.9851 - acc: 0.5372 - val_loss: 0.9657 - val_acc: 0.5143\n",
      "Epoch 5/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.9191 - acc: 0.6439 - val_loss: 0.9076 - val_acc: 0.5692\n",
      "Epoch 6/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.8512 - acc: 0.7043 - val_loss: 0.8453 - val_acc: 0.6701\n",
      "Epoch 7/60\n",
      "15663/15663 [==============================] - 8s - loss: 0.7873 - acc: 0.7395 - val_loss: 0.7933 - val_acc: 0.7040\n",
      "Epoch 8/60\n",
      "15663/15663 [==============================] - 11s - loss: 0.7307 - acc: 0.7633 - val_loss: 0.7467 - val_acc: 0.7232\n",
      "Epoch 9/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.6804 - acc: 0.7804 - val_loss: 0.7078 - val_acc: 0.7398\n",
      "Epoch 10/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.6363 - acc: 0.7954 - val_loss: 0.6765 - val_acc: 0.7344\n",
      "Epoch 11/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.5961 - acc: 0.8085 - val_loss: 0.6439 - val_acc: 0.7582\n",
      "Epoch 12/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.5612 - acc: 0.8189 - val_loss: 0.6211 - val_acc: 0.7582\n",
      "Epoch 13/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.5292 - acc: 0.8290 - val_loss: 0.5937 - val_acc: 0.7768\n",
      "Epoch 14/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.5006 - acc: 0.8396 - val_loss: 0.5755 - val_acc: 0.7860\n",
      "Epoch 15/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.4737 - acc: 0.8486 - val_loss: 0.5581 - val_acc: 0.7909\n",
      "Epoch 16/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.4490 - acc: 0.8565 - val_loss: 0.5399 - val_acc: 0.7929\n",
      "Epoch 17/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.4265 - acc: 0.8647 - val_loss: 0.5270 - val_acc: 0.7983\n",
      "Epoch 18/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.4060 - acc: 0.8724 - val_loss: 0.5089 - val_acc: 0.8075\n",
      "Epoch 19/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.3850 - acc: 0.8803 - val_loss: 0.4967 - val_acc: 0.8044\n",
      "Epoch 20/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.3663 - acc: 0.8870 - val_loss: 0.4840 - val_acc: 0.8159\n",
      "Epoch 21/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.3496 - acc: 0.8920 - val_loss: 0.4774 - val_acc: 0.8146\n",
      "Epoch 22/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.3334 - acc: 0.8989 - val_loss: 0.4643 - val_acc: 0.8207\n",
      "Epoch 23/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.3186 - acc: 0.9017 - val_loss: 0.4560 - val_acc: 0.8169\n",
      "Epoch 24/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.3035 - acc: 0.9096 - val_loss: 0.4539 - val_acc: 0.8230\n",
      "Epoch 25/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.2907 - acc: 0.9135 - val_loss: 0.4368 - val_acc: 0.8297\n",
      "Epoch 26/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.2782 - acc: 0.9178 - val_loss: 0.4294 - val_acc: 0.8304\n",
      "Epoch 27/60\n",
      "15663/15663 [==============================] - 14s - loss: 0.2662 - acc: 0.9215 - val_loss: 0.4222 - val_acc: 0.8335\n",
      "Epoch 28/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.2544 - acc: 0.9238 - val_loss: 0.4212 - val_acc: 0.8343\n",
      "Epoch 29/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.2448 - acc: 0.9275 - val_loss: 0.4134 - val_acc: 0.8361\n",
      "Epoch 30/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.2342 - acc: 0.9320 - val_loss: 0.4094 - val_acc: 0.8396\n",
      "Epoch 31/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.2247 - acc: 0.9356 - val_loss: 0.4039 - val_acc: 0.8404\n",
      "Epoch 32/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.2163 - acc: 0.9370 - val_loss: 0.3988 - val_acc: 0.8417\n",
      "Epoch 33/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.2075 - acc: 0.9418 - val_loss: 0.3935 - val_acc: 0.8437\n",
      "Epoch 34/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1995 - acc: 0.9431 - val_loss: 0.3915 - val_acc: 0.8437\n",
      "Epoch 35/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1915 - acc: 0.9452 - val_loss: 0.3884 - val_acc: 0.8453\n",
      "Epoch 36/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1848 - acc: 0.9476 - val_loss: 0.3862 - val_acc: 0.8478\n",
      "Epoch 37/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.1780 - acc: 0.9510 - val_loss: 0.3860 - val_acc: 0.8465\n",
      "Epoch 38/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.1717 - acc: 0.9524 - val_loss: 0.3807 - val_acc: 0.8486\n",
      "Epoch 39/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1643 - acc: 0.9547 - val_loss: 0.3799 - val_acc: 0.8496\n",
      "Epoch 40/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1594 - acc: 0.9562 - val_loss: 0.3759 - val_acc: 0.8519\n",
      "Epoch 41/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.1532 - acc: 0.9579 - val_loss: 0.3791 - val_acc: 0.8519\n",
      "Epoch 42/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1482 - acc: 0.9594 - val_loss: 0.3734 - val_acc: 0.8529\n",
      "Epoch 43/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.1433 - acc: 0.9617 - val_loss: 0.3778 - val_acc: 0.8509\n",
      "Epoch 44/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.1369 - acc: 0.9640 - val_loss: 0.3748 - val_acc: 0.8511.96\n",
      "Epoch 45/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.1329 - acc: 0.9650 - val_loss: 0.3729 - val_acc: 0.8524\n",
      "Epoch 46/60\n",
      "15663/15663 [==============================] - 14s - loss: 0.1283 - acc: 0.9663 - val_loss: 0.3743 - val_acc: 0.8529\n",
      "Epoch 47/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.1237 - acc: 0.9661 - val_loss: 0.3747 - val_acc: 0.8527\n",
      "Epoch 48/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.1199 - acc: 0.9674 - val_loss: 0.3754 - val_acc: 0.8524\n",
      "Epoch 49/60\n",
      "15663/15663 [==============================] - 10s - loss: 0.1157 - acc: 0.9695 - val_loss: 0.3705 - val_acc: 0.8555\n",
      "Epoch 50/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.1118 - acc: 0.9708 - val_loss: 0.3907 - val_acc: 0.8414\n",
      "Epoch 51/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1088 - acc: 0.9708 - val_loss: 0.3732 - val_acc: 0.8506\n",
      "Epoch 52/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1047 - acc: 0.9720 - val_loss: 0.3743 - val_acc: 0.8529\n",
      "Epoch 53/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1012 - acc: 0.9732 - val_loss: 0.3726 - val_acc: 0.8516\n",
      "Epoch 54/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.0988 - acc: 0.9731 - val_loss: 0.3791 - val_acc: 0.8481\n",
      "3584/3916 [==========================>...] - ETA: 0svalLoss: 0.3704988771061335\n",
      "7584/8392 [==========================>...] - ETA: 0s2/5: #Trains: 15663, #Val: 3916 (15663, 512) (3916, 512) (8392, 512)\n",
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/60\n",
      "15663/15663 [==============================] - 13s - loss: 1.0851 - acc: 0.4036 - val_loss: 1.0810 - val_acc: 0.4037\n",
      "Epoch 2/60\n",
      "15663/15663 [==============================] - 12s - loss: 1.0726 - acc: 0.4065 - val_loss: 1.0622 - val_acc: 0.4145\n",
      "Epoch 3/60\n",
      "15663/15663 [==============================] - 12s - loss: 1.0430 - acc: 0.4376 - val_loss: 1.0226 - val_acc: 0.4732\n",
      "Epoch 4/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.9904 - acc: 0.5278 - val_loss: 0.9656 - val_acc: 0.5945\n",
      "Epoch 5/60\n",
      "15663/15663 [==============================] - 14s - loss: 0.9222 - acc: 0.6247 - val_loss: 0.8980 - val_acc: 0.6680\n",
      "Epoch 6/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.8505 - acc: 0.6914 - val_loss: 0.8376 - val_acc: 0.6412\n",
      "Epoch 7/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.7831 - acc: 0.7357 - val_loss: 0.7770 - val_acc: 0.7395\n",
      "Epoch 8/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.7226 - acc: 0.7633 - val_loss: 0.7292 - val_acc: 0.7569\n",
      "Epoch 9/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.6704 - acc: 0.7797 - val_loss: 0.6886 - val_acc: 0.7666\n",
      "Epoch 10/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.6243 - acc: 0.7959 - val_loss: 0.6526 - val_acc: 0.7684\n",
      "Epoch 11/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.5832 - acc: 0.8085 - val_loss: 0.6206 - val_acc: 0.7740\n",
      "Epoch 12/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.5459 - acc: 0.8236 - val_loss: 0.5974 - val_acc: 0.7755\n",
      "Epoch 13/60\n",
      "15663/15663 [==============================] - 11s - loss: 0.5128 - acc: 0.8326 - val_loss: 0.5696 - val_acc: 0.7855\n",
      "Epoch 14/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.4817 - acc: 0.8444 - val_loss: 0.5472 - val_acc: 0.7932\n",
      "Epoch 15/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.4537 - acc: 0.8555 - val_loss: 0.5288 - val_acc: 0.8039\n",
      "Epoch 16/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.4277 - acc: 0.8639 - val_loss: 0.5164 - val_acc: 0.8044\n",
      "Epoch 17/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.4038 - acc: 0.8731 - val_loss: 0.4995 - val_acc: 0.8026\n",
      "Epoch 18/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.3820 - acc: 0.8777 - val_loss: 0.4828 - val_acc: 0.8136\n",
      "Epoch 19/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.3604 - acc: 0.8879 - val_loss: 0.4755 - val_acc: 0.8166\n",
      "Epoch 20/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.3410 - acc: 0.8956 - val_loss: 0.4612 - val_acc: 0.8149\n",
      "Epoch 21/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.3232 - acc: 0.9006 - val_loss: 0.4441 - val_acc: 0.8307\n",
      "Epoch 22/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.3071 - acc: 0.9063 - val_loss: 0.4339 - val_acc: 0.8315\n",
      "Epoch 23/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.2917 - acc: 0.9122 - val_loss: 0.4286 - val_acc: 0.8366\n",
      "Epoch 24/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.2775 - acc: 0.9169 - val_loss: 0.4233 - val_acc: 0.8284\n",
      "Epoch 25/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.2630 - acc: 0.9226 - val_loss: 0.4134 - val_acc: 0.8394\n",
      "Epoch 26/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.2505 - acc: 0.9259 - val_loss: 0.4058 - val_acc: 0.8371\n",
      "Epoch 27/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.2394 - acc: 0.9291 - val_loss: 0.4119 - val_acc: 0.8394\n",
      "Epoch 28/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.2288 - acc: 0.9333 - val_loss: 0.3936 - val_acc: 0.8491\n",
      "Epoch 29/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.2171 - acc: 0.9375 - val_loss: 0.3909 - val_acc: 0.8493\n",
      "Epoch 30/60\n",
      "15663/15663 [==============================] - 11s - loss: 0.2077 - acc: 0.9383 - val_loss: 0.3833 - val_acc: 0.8506\n",
      "Epoch 31/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1975 - acc: 0.9434 - val_loss: 0.3887 - val_acc: 0.8404\n",
      "Epoch 32/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.1896 - acc: 0.9450 - val_loss: 0.3876 - val_acc: 0.8458\n",
      "Epoch 33/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1822 - acc: 0.9468 - val_loss: 0.3732 - val_acc: 0.8537\n",
      "Epoch 34/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1736 - acc: 0.9483 - val_loss: 0.3733 - val_acc: 0.8519\n",
      "Epoch 35/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.1665 - acc: 0.9516 - val_loss: 0.3724 - val_acc: 0.8557\n",
      "Epoch 36/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.1601 - acc: 0.9539 - val_loss: 0.3762 - val_acc: 0.8491\n",
      "Epoch 37/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1530 - acc: 0.9553 - val_loss: 0.3660 - val_acc: 0.8542\n",
      "Epoch 38/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.1464 - acc: 0.9582 - val_loss: 0.3749 - val_acc: 0.8498\n",
      "Epoch 39/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1404 - acc: 0.9605 - val_loss: 0.3721 - val_acc: 0.8542\n",
      "Epoch 40/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.1356 - acc: 0.9614 - val_loss: 0.3656 - val_acc: 0.8583\n",
      "Epoch 41/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1294 - acc: 0.9638 - val_loss: 0.3768 - val_acc: 0.8506\n",
      "Epoch 42/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1243 - acc: 0.9657 - val_loss: 0.3708 - val_acc: 0.8575\n",
      "Epoch 43/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.1200 - acc: 0.9662 - val_loss: 0.3669 - val_acc: 0.8593\n",
      "Epoch 44/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1154 - acc: 0.9680 - val_loss: 0.3661 - val_acc: 0.8550\n",
      "Epoch 45/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.1106 - acc: 0.9696 - val_loss: 0.3668 - val_acc: 0.8552\n",
      "3584/3916 [==========================>...] - ETA: 0svalLoss: 0.368047200684835\n",
      "8320/8392 [============================>.] - ETA: 0s3/5: #Trains: 15663, #Val: 3916 (15663, 512) (3916, 512) (8392, 512)\n",
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/60\n",
      "15663/15663 [==============================] - 14s - loss: 1.0859 - acc: 0.4008 - val_loss: 1.0789 - val_acc: 0.4096\n",
      "Epoch 2/60\n",
      "15663/15663 [==============================] - 13s - loss: 1.0738 - acc: 0.4046 - val_loss: 1.0622 - val_acc: 0.4096\n",
      "Epoch 3/60\n",
      "15663/15663 [==============================] - 13s - loss: 1.0443 - acc: 0.4333 - val_loss: 1.0221 - val_acc: 0.4729\n",
      "Epoch 4/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.9925 - acc: 0.5177 - val_loss: 0.9691 - val_acc: 0.6264\n",
      "Epoch 5/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.9272 - acc: 0.6167 - val_loss: 0.9081 - val_acc: 0.6726\n",
      "Epoch 6/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.8583 - acc: 0.6919 - val_loss: 0.8480 - val_acc: 0.6427\n",
      "Epoch 7/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.7925 - acc: 0.7357 - val_loss: 0.7895 - val_acc: 0.6936\n",
      "Epoch 8/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.7331 - acc: 0.7585 - val_loss: 0.7451 - val_acc: 0.7515\n",
      "Epoch 9/60\n",
      "15663/15663 [==============================] - 13s - loss: 0.6822 - acc: 0.7781 - val_loss: 0.7034 - val_acc: 0.7326\n",
      "Epoch 10/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.6359 - acc: 0.7917 - val_loss: 0.6687 - val_acc: 0.7523\n",
      "Epoch 11/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.5963 - acc: 0.8050 - val_loss: 0.6381 - val_acc: 0.7653\n",
      "Epoch 12/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.5599 - acc: 0.8173 - val_loss: 0.6169 - val_acc: 0.7786\n",
      "Epoch 13/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.5266 - acc: 0.8311 - val_loss: 0.5906 - val_acc: 0.7755\n",
      "Epoch 14/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.4977 - acc: 0.8353 - val_loss: 0.5686 - val_acc: 0.7937\n",
      "Epoch 15/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.4701 - acc: 0.8469 - val_loss: 0.5504 - val_acc: 0.7995\n",
      "Epoch 16/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.4448 - acc: 0.8571 - val_loss: 0.5362 - val_acc: 0.7914\n",
      "Epoch 17/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.4209 - acc: 0.8646 - val_loss: 0.5181 - val_acc: 0.8016\n",
      "Epoch 18/60\n",
      "15663/15663 [==============================] - 12s - loss: 0.3990 - acc: 0.8722 - val_loss: 0.5055 - val_acc: 0.8085\n",
      "Epoch 19/60\n",
      "15663/15663 [==============================] - 8s - loss: 0.3795 - acc: 0.8800 - val_loss: 0.4922 - val_acc: 0.8154\n",
      "Epoch 20/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.3603 - acc: 0.8877 - val_loss: 0.4844 - val_acc: 0.8123\n",
      "Epoch 21/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.3425 - acc: 0.8940 - val_loss: 0.4718 - val_acc: 0.8220\n",
      "Epoch 22/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.3260 - acc: 0.9003 - val_loss: 0.4552 - val_acc: 0.8294\n",
      "Epoch 23/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15663/15663 [==============================] - 7s - loss: 0.3102 - acc: 0.9056 - val_loss: 0.4466 - val_acc: 0.8309\n",
      "Epoch 24/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.2957 - acc: 0.9116 - val_loss: 0.4387 - val_acc: 0.8299\n",
      "Epoch 25/60\n",
      "15663/15663 [==============================] - 8s - loss: 0.2814 - acc: 0.9157 - val_loss: 0.4304 - val_acc: 0.8345\n",
      "Epoch 26/60\n",
      "15663/15663 [==============================] - 8s - loss: 0.2681 - acc: 0.9208 - val_loss: 0.4226 - val_acc: 0.8368\n",
      "Epoch 27/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.2564 - acc: 0.9250 - val_loss: 0.4206 - val_acc: 0.8376\n",
      "Epoch 28/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.2448 - acc: 0.9280 - val_loss: 0.4106 - val_acc: 0.8399\n",
      "Epoch 29/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.2345 - acc: 0.9323 - val_loss: 0.4051 - val_acc: 0.8424\n",
      "Epoch 30/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.2243 - acc: 0.9349 - val_loss: 0.4053 - val_acc: 0.8422\n",
      "Epoch 31/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.2146 - acc: 0.9379 - val_loss: 0.3958 - val_acc: 0.8442\n",
      "Epoch 32/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.2059 - acc: 0.9406 - val_loss: 0.3927 - val_acc: 0.8455\n",
      "Epoch 33/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1970 - acc: 0.9439 - val_loss: 0.3953 - val_acc: 0.8424\n",
      "Epoch 34/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1895 - acc: 0.9458 - val_loss: 0.3941 - val_acc: 0.8460\n",
      "Epoch 35/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1808 - acc: 0.9489 - val_loss: 0.3827 - val_acc: 0.8509\n",
      "Epoch 36/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1733 - acc: 0.9508 - val_loss: 0.3856 - val_acc: 0.8465\n",
      "Epoch 37/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.1672 - acc: 0.9524 - val_loss: 0.3775 - val_acc: 0.8498\n",
      "Epoch 38/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.1611 - acc: 0.9536 - val_loss: 0.3762 - val_acc: 0.8511\n",
      "Epoch 39/60\n",
      "15663/15663 [==============================] - 8s - loss: 0.1540 - acc: 0.9568 - val_loss: 0.3740 - val_acc: 0.8524\n",
      "Epoch 40/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1489 - acc: 0.9579 - val_loss: 0.3733 - val_acc: 0.8527\n",
      "Epoch 41/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1427 - acc: 0.9599 - val_loss: 0.3765 - val_acc: 0.8488\n",
      "Epoch 42/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1384 - acc: 0.9614 - val_loss: 0.3843 - val_acc: 0.8422\n",
      "Epoch 43/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1325 - acc: 0.9625 - val_loss: 0.3769 - val_acc: 0.8516\n",
      "Epoch 44/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.1276 - acc: 0.9650 - val_loss: 0.3800 - val_acc: 0.8468\n",
      "Epoch 45/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1241 - acc: 0.9654 - val_loss: 0.3709 - val_acc: 0.8542\n",
      "Epoch 46/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.1191 - acc: 0.9668 - val_loss: 0.3707 - val_acc: 0.8516\n",
      "Epoch 47/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.1148 - acc: 0.9691 - val_loss: 0.3862 - val_acc: 0.8453\n",
      "Epoch 48/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1109 - acc: 0.9685 - val_loss: 0.3721 - val_acc: 0.8547\n",
      "Epoch 49/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1060 - acc: 0.9703 - val_loss: 0.3872 - val_acc: 0.8463\n",
      "Epoch 50/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.1028 - acc: 0.9716 - val_loss: 0.3837 - val_acc: 0.8491\n",
      "Epoch 51/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1000 - acc: 0.9719 - val_loss: 0.3790 - val_acc: 0.8486\n",
      "2368/3916 [=================>............] - ETA: 0svalLoss: 0.3689423644471959\n",
      "7072/8392 [========================>.....] - ETA: 0s4/5: #Trains: 15663, #Val: 3916 (15663, 512) (3916, 512) (8392, 512)\n",
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/60\n",
      "15663/15663 [==============================] - 6s - loss: 1.0842 - acc: 0.4047 - val_loss: 1.0813 - val_acc: 0.3996\n",
      "Epoch 2/60\n",
      "15663/15663 [==============================] - 6s - loss: 1.0657 - acc: 0.4135 - val_loss: 1.0564 - val_acc: 0.4538\n",
      "Epoch 3/60\n",
      "15663/15663 [==============================] - 7s - loss: 1.0235 - acc: 0.4877 - val_loss: 1.0137 - val_acc: 0.5084\n",
      "Epoch 4/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.9646 - acc: 0.5481 - val_loss: 0.9554 - val_acc: 0.5128\n",
      "Epoch 5/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.8973 - acc: 0.6094 - val_loss: 0.8970 - val_acc: 0.5975\n",
      "Epoch 6/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.8303 - acc: 0.6772 - val_loss: 0.8394 - val_acc: 0.7089\n",
      "Epoch 7/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.7668 - acc: 0.7350 - val_loss: 0.7914 - val_acc: 0.6601\n",
      "Epoch 8/60\n",
      "15663/15663 [==============================] - 8s - loss: 0.7094 - acc: 0.7636 - val_loss: 0.7398 - val_acc: 0.7245\n",
      "Epoch 9/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.6582 - acc: 0.7841 - val_loss: 0.6987 - val_acc: 0.7566\n",
      "Epoch 10/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.6131 - acc: 0.8007 - val_loss: 0.6635 - val_acc: 0.7617\n",
      "Epoch 11/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.5732 - acc: 0.8146 - val_loss: 0.6317 - val_acc: 0.7735\n",
      "Epoch 12/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.5385 - acc: 0.8240 - val_loss: 0.6037 - val_acc: 0.7840\n",
      "Epoch 13/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.5057 - acc: 0.8353 - val_loss: 0.5796 - val_acc: 0.7926\n",
      "Epoch 14/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.4772 - acc: 0.8476 - val_loss: 0.5588 - val_acc: 0.7916\n",
      "Epoch 15/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.4496 - acc: 0.8563 - val_loss: 0.5386 - val_acc: 0.8044\n",
      "Epoch 16/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.4250 - acc: 0.8631 - val_loss: 0.5217 - val_acc: 0.8034\n",
      "Epoch 17/60\n",
      "15663/15663 [==============================] - 8s - loss: 0.4023 - acc: 0.8719 - val_loss: 0.5033 - val_acc: 0.8144\n",
      "Epoch 18/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.3805 - acc: 0.8775 - val_loss: 0.4928 - val_acc: 0.8164\n",
      "Epoch 19/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.3616 - acc: 0.8869 - val_loss: 0.4762 - val_acc: 0.8202\n",
      "Epoch 20/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.3432 - acc: 0.8918 - val_loss: 0.4632 - val_acc: 0.8256\n",
      "Epoch 21/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.3263 - acc: 0.8972 - val_loss: 0.4535 - val_acc: 0.8266\n",
      "Epoch 22/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.3094 - acc: 0.9055 - val_loss: 0.4401 - val_acc: 0.8368\n",
      "Epoch 23/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.2943 - acc: 0.9098 - val_loss: 0.4388 - val_acc: 0.8269\n",
      "Epoch 24/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.2805 - acc: 0.9149 - val_loss: 0.4227 - val_acc: 0.8368\n",
      "Epoch 25/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.2671 - acc: 0.9206 - val_loss: 0.4193 - val_acc: 0.8396\n",
      "Epoch 26/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.2546 - acc: 0.9227 - val_loss: 0.4099 - val_acc: 0.8394\n",
      "Epoch 27/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.2421 - acc: 0.9270 - val_loss: 0.4021 - val_acc: 0.8437\n",
      "Epoch 28/60\n",
      "15663/15663 [==============================] - 8s - loss: 0.2314 - acc: 0.9309 - val_loss: 0.3972 - val_acc: 0.8435\n",
      "Epoch 29/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.2216 - acc: 0.9333 - val_loss: 0.4001 - val_acc: 0.8414\n",
      "Epoch 30/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.2109 - acc: 0.9367 - val_loss: 0.3896 - val_acc: 0.8501\n",
      "Epoch 31/60\n",
      "15663/15663 [==============================] - 8s - loss: 0.2018 - acc: 0.9402 - val_loss: 0.3856 - val_acc: 0.8460\n",
      "Epoch 32/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.1928 - acc: 0.9439 - val_loss: 0.3826 - val_acc: 0.8470\n",
      "Epoch 33/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.1845 - acc: 0.9470 - val_loss: 0.3753 - val_acc: 0.8527\n",
      "Epoch 34/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1770 - acc: 0.9476 - val_loss: 0.3748 - val_acc: 0.8527\n",
      "Epoch 35/60\n",
      "15663/15663 [==============================] - 8s - loss: 0.1693 - acc: 0.9515 - val_loss: 0.3731 - val_acc: 0.8547\n",
      "Epoch 36/60\n",
      "15663/15663 [==============================] - 9s - loss: 0.1623 - acc: 0.9536 - val_loss: 0.3707 - val_acc: 0.8506\n",
      "Epoch 37/60\n",
      "15663/15663 [==============================] - 8s - loss: 0.1555 - acc: 0.9549 - val_loss: 0.3850 - val_acc: 0.8432\n",
      "Epoch 38/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.1491 - acc: 0.9569 - val_loss: 0.3723 - val_acc: 0.8550\n",
      "Epoch 39/60\n",
      "15663/15663 [==============================] - 8s - loss: 0.1433 - acc: 0.9591 - val_loss: 0.3768 - val_acc: 0.8532\n",
      "Epoch 40/60\n",
      "15663/15663 [==============================] - 5s - loss: 0.1374 - acc: 0.9627 - val_loss: 0.3768 - val_acc: 0.8516\n",
      "Epoch 41/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.1317 - acc: 0.9630 - val_loss: 0.3634 - val_acc: 0.8562\n",
      "Epoch 42/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.1273 - acc: 0.9648 - val_loss: 0.3668 - val_acc: 0.8557\n",
      "Epoch 43/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1210 - acc: 0.9679 - val_loss: 0.3633 - val_acc: 0.8552\n",
      "Epoch 44/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1169 - acc: 0.9673 - val_loss: 0.3646 - val_acc: 0.8567\n",
      "Epoch 45/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1120 - acc: 0.9692 - val_loss: 0.3745 - val_acc: 0.8527\n",
      "Epoch 46/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1085 - acc: 0.9702 - val_loss: 0.3683 - val_acc: 0.8547\n",
      "Epoch 47/60\n",
      "15663/15663 [==============================] - 6s - loss: 0.1043 - acc: 0.9730 - val_loss: 0.3676 - val_acc: 0.8560\n",
      "Epoch 48/60\n",
      "15663/15663 [==============================] - 7s - loss: 0.1007 - acc: 0.9735 - val_loss: 0.3753 - val_acc: 0.8509\n",
      "3916/3916 [==============================] - 0s     \n",
      "valLoss: 0.36752529014408947\n",
      "7872/8392 [===========================>..] - ETA: 0s5/5: #Trains: 15664, #Val: 3915 (15664, 512) (3915, 512) (8392, 512)\n",
      "Train on 15664 samples, validate on 3915 samples\n",
      "Epoch 1/60\n",
      "15664/15664 [==============================] - 8s - loss: 1.0849 - acc: 0.4024 - val_loss: 1.0818 - val_acc: 0.4020\n",
      "Epoch 2/60\n",
      "15664/15664 [==============================] - 8s - loss: 1.0712 - acc: 0.4060 - val_loss: 1.0603 - val_acc: 0.4143\n",
      "Epoch 3/60\n",
      "15664/15664 [==============================] - 6s - loss: 1.0365 - acc: 0.4532 - val_loss: 1.0185 - val_acc: 0.4391\n",
      "Epoch 4/60\n",
      "15664/15664 [==============================] - 8s - loss: 0.9823 - acc: 0.5425 - val_loss: 0.9612 - val_acc: 0.5706\n",
      "Epoch 5/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.9168 - acc: 0.6419 - val_loss: 0.9011 - val_acc: 0.6521\n",
      "Epoch 6/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.8504 - acc: 0.6969 - val_loss: 0.8421 - val_acc: 0.6725\n",
      "Epoch 7/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.7877 - acc: 0.7346 - val_loss: 0.7898 - val_acc: 0.7060\n",
      "Epoch 8/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.7311 - acc: 0.7587 - val_loss: 0.7438 - val_acc: 0.7535\n",
      "Epoch 9/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.6803 - acc: 0.7757 - val_loss: 0.7082 - val_acc: 0.7221\n",
      "Epoch 10/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.6356 - acc: 0.7906 - val_loss: 0.6679 - val_acc: 0.7653\n",
      "Epoch 11/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.5963 - acc: 0.8043 - val_loss: 0.6385 - val_acc: 0.7681\n",
      "Epoch 12/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.5603 - acc: 0.8159 - val_loss: 0.6235 - val_acc: 0.7757\n",
      "Epoch 13/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.5277 - acc: 0.8290 - val_loss: 0.5895 - val_acc: 0.7883\n",
      "Epoch 14/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.4984 - acc: 0.8378 - val_loss: 0.5870 - val_acc: 0.7880\n",
      "Epoch 15/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.4711 - acc: 0.8491 - val_loss: 0.5489 - val_acc: 0.7977\n",
      "Epoch 16/60\n",
      "15664/15664 [==============================] - 8s - loss: 0.4455 - acc: 0.8575 - val_loss: 0.5336 - val_acc: 0.8100\n",
      "Epoch 17/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.4217 - acc: 0.8645 - val_loss: 0.5157 - val_acc: 0.8133\n",
      "Epoch 18/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.4013 - acc: 0.8709 - val_loss: 0.5102 - val_acc: 0.8125\n",
      "Epoch 19/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.3795 - acc: 0.8799 - val_loss: 0.4901 - val_acc: 0.8235\n",
      "Epoch 20/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.3614 - acc: 0.8862 - val_loss: 0.4813 - val_acc: 0.8232\n",
      "Epoch 21/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.3438 - acc: 0.8954 - val_loss: 0.4702 - val_acc: 0.8194\n",
      "Epoch 22/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.3270 - acc: 0.8990 - val_loss: 0.4613 - val_acc: 0.8202\n",
      "Epoch 23/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.3117 - acc: 0.9055 - val_loss: 0.4567 - val_acc: 0.8248\n",
      "Epoch 24/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.2965 - acc: 0.9117 - val_loss: 0.4455 - val_acc: 0.8261\n",
      "Epoch 25/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.2828 - acc: 0.9156 - val_loss: 0.4368 - val_acc: 0.8268\n",
      "Epoch 26/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.2703 - acc: 0.9207 - val_loss: 0.4335 - val_acc: 0.8342\n",
      "Epoch 27/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.2586 - acc: 0.9240 - val_loss: 0.4325 - val_acc: 0.8322\n",
      "Epoch 28/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.2473 - acc: 0.9295 - val_loss: 0.4176 - val_acc: 0.8388\n",
      "Epoch 29/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.2371 - acc: 0.9311 - val_loss: 0.4160 - val_acc: 0.8386\n",
      "Epoch 30/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.2267 - acc: 0.9352 - val_loss: 0.4132 - val_acc: 0.8393\n",
      "Epoch 31/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.2176 - acc: 0.9386 - val_loss: 0.4044 - val_acc: 0.8427\n",
      "Epoch 32/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.2083 - acc: 0.9394 - val_loss: 0.4019 - val_acc: 0.8429\n",
      "Epoch 33/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.1998 - acc: 0.9425 - val_loss: 0.4048 - val_acc: 0.8429\n",
      "Epoch 34/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.1918 - acc: 0.9457 - val_loss: 0.4013 - val_acc: 0.8322\n",
      "Epoch 35/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.1841 - acc: 0.9489 - val_loss: 0.3962 - val_acc: 0.8421\n",
      "Epoch 36/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.1766 - acc: 0.9505 - val_loss: 0.3917 - val_acc: 0.8427\n",
      "Epoch 37/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.1697 - acc: 0.9535 - val_loss: 0.4118 - val_acc: 0.8398\n",
      "Epoch 38/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.1643 - acc: 0.9546 - val_loss: 0.3873 - val_acc: 0.8460\n",
      "Epoch 39/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.1576 - acc: 0.9561 - val_loss: 0.3907 - val_acc: 0.8416\n",
      "Epoch 40/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.1517 - acc: 0.9577 - val_loss: 0.3885 - val_acc: 0.8452\n",
      "Epoch 41/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.1455 - acc: 0.9591 - val_loss: 0.3841 - val_acc: 0.8493\n",
      "Epoch 42/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.1400 - acc: 0.9611 - val_loss: 0.3899 - val_acc: 0.8478\n",
      "Epoch 43/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.1358 - acc: 0.9617 - val_loss: 0.3835 - val_acc: 0.8483\n",
      "Epoch 44/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.1312 - acc: 0.9632 - val_loss: 0.4075 - val_acc: 0.8373\n",
      "Epoch 45/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.1262 - acc: 0.9649 - val_loss: 0.3867 - val_acc: 0.8467\n",
      "Epoch 46/60\n",
      "15664/15664 [==============================] - 7s - loss: 0.1208 - acc: 0.9671 - val_loss: 0.3886 - val_acc: 0.8493\n",
      "Epoch 47/60\n",
      "15664/15664 [==============================] - 6s - loss: 0.1176 - acc: 0.9675 - val_loss: 0.3870 - val_acc: 0.8457\n",
      "Epoch 48/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15664/15664 [==============================] - 6s - loss: 0.1137 - acc: 0.9685 - val_loss: 0.3953 - val_acc: 0.8490\n",
      "2784/3915 [====================>.........] - ETA: 0svalLoss: 0.370715458382598\n",
      "7840/8392 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "input_dim = np.max(x) + 1\n",
    "\n",
    "# for next training\n",
    "predict_prob_features = np.zeros((len(df_train), 3))\n",
    "predict_prob_features_test = np.zeros((len(df_test), 3))\n",
    "\n",
    "# training parameters\n",
    "seed = 7\n",
    "num_split = 5\n",
    "epochs = 60\n",
    "\n",
    "ite = 0\n",
    "sum_loss = 0.\n",
    "losses = []\n",
    "\n",
    "kf = KFold(n_splits=num_split, random_state=seed, shuffle=True)\n",
    "for train_index, val_index in kf.split(x):\n",
    "    ite += 1\n",
    "    print('{}/{}: #Trains: {}, #Val: {}'.format(ite, num_split, len(train_index), len(val_index)), end=' ')\n",
    "    \n",
    "    x_train = x[train_index]\n",
    "    x_val = x[val_index]\n",
    "\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    print(x_train.shape, x_val.shape, x_test.shape)\n",
    "    \n",
    "    model = create_fastText_model(input_dim, embedding_dim=10, optimizer='adam')\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath='./../fasttext_weights/weights.hdf5', verbose=0, save_best_only=True)\n",
    "\n",
    "    hist = model.fit(x_train, y_train,\n",
    "                     batch_size=16,\n",
    "                     validation_data=(x_val, y_val),\n",
    "                     epochs=epochs,\n",
    "                     callbacks=[EarlyStopping(patience=4, monitor='val_loss'), checkpointer]\n",
    "                    )\n",
    "\n",
    "    # load best weights\n",
    "    model.load_weights('./../fasttext_weights/weights.hdf5')\n",
    "    y_pred = model.predict_proba(x_val)\n",
    "    l = log_loss(y_pred=y_pred, y_true=np.nonzero(y_val)[1])\n",
    "    losses.append(l)\n",
    "    sum_loss += l\n",
    "    \n",
    "    print('valLoss: {}'.format(sum_loss/ite))\n",
    "\n",
    "    # save features\n",
    "    predict_prob_features[val_index] = y_pred\n",
    "    predict_prob_features_test += model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for a, c in author2class.items():\n",
    "    df_train['{}_fasttext_unigram'.format(a)] = predict_prob_features[:, c]\n",
    "    df_test['{}_fasttext_unigram'.format(a)] = predict_prob_features_test[:, c]/num_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('./../data/train_feature.csv', index=False)\n",
    "df_test.to_csv('./../data/test_feature.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
